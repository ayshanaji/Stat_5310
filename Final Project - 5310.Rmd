---
title: "Stat_5310 Project"
author: "Ayisha - TRU- T00727585"
date: "`r Sys.Date()`"
output: html_document
---
### A comparitive study between the Frequentist and Bayesian Approach to Photons 
### Single Photons generated####
```{r}
# Set seed for reproducibility
set.seed(1)

# True flux and number of measurements
F_true <- 1000
N <- 50

# Generating simple photon count data
F_simple <- rpois(N, F_true)
e_simple <- sqrt(F_simple)

# Visualization for simple photon counts
plot(y = 1:N, x = F_simple, pch = 16, xlab = "Flux", ylab = "Measurement Number",
     main = "Simple Photon Count Data", ylim = c(0, N + 1), yaxt = "n")
arrows(x0 = F_simple - e_simple, x1 = F_simple + e_simple, y0 = 1:N, y1 = 1:N, angle = 90, code = 3, length = 0.1)
abline(v = F_true, col = "red", lty = 2, lw = 2)
axis(2, at = 1:N, labels = 1:N)
```


###Frequentist Approach to Single photons 
```{r}
# Function to compute negative log-likelihood (for optimization)
neg_log_likelihood <- function(F_true, F_obs, e_obs) {
  N <- length(F_obs)
  log_L <- -N / 2 * log(2 * pi) - sum(log(e_obs)) - sum((F_obs - F_true)^2 / (2 * e_obs^2))
  return(log_L)
}

# Set seed for reproducibility
set.seed(1)

# True flux and number of measurements
F_true <- 1000
N <- 50

# Generating simple photon count data
F_simple <- rpois(N, F_true)
e_simple <- sqrt(F_simple)

# MLE optimization using optim function
mle_result <- optim(par = F_true, fn = neg_log_likelihood, F_obs = F_simple, e_obs = e_simple, method = "BFGS")

# MLE estimate of the photon flux
F_mle <- mle_result$par


se_mle <- sqrt(F_mle/N)

# 95% confidence interval
ci_mle <- c(F_mle - 1.96 * se_mle, F_mle + 1.96 * se_mle)

# Output results
cat("MLE Estimate of Photon Flux:", F_mle, "\n")
cat("Standard Error of MLE Estimate:", se_mle, "\n")
cat("95% Confidence Interval:", ci_mle, "\n")
```


#### Confidence Interval Plot####
```{r}
# Plot the likelihood values
plot(F_simple, dnorm(F_simple, mean = F_mle, sd = se_mle), type = "l", col = "blue",
     xlab = "Photon Flux", ylab = "Likelihood", main = "MLE Estimate and Likelihood Values")

# Mark the MLE estimate on the plot
points(F_mle, dnorm(F_mle, mean = F_mle, sd = se_mle), col = "red", pch = 16)

# Add confidence interval lines
abline(v = ci_mle[1], col = "green", lty = 2, lwd = 2)
abline(v = ci_mle[2], col = "green", lty = 2, lwd = 2)

# Add legend
legend("topright", legend = c("Likelihood", "MLE Estimate", "95% Confidence Interval"),
       col = c("blue", "red", "green"), lty = 1:2, cex = 0.8)

# Show the plot

```

#### Bayesian Approach to single Photons ####

### uniform Prior - Flat prior###
```{r}
# Define log prior, likelihood, and posterior functions with flat (uniform) prior
log_prior_uniform <- function(theta) {
  return(0)  # Flat (uniform) prior
}

log_likelihood <- function(theta, F, e) {
  return(-0.5 * sum(log(2 * pi * e^2) + (F - theta)^2 / e^2))
}

log_posterior_uniform <- function(theta, F, e) {
  return(log_prior_uniform(theta) + log_likelihood(theta, F, e))
}

# Metropolis-Hastings MCMC algorithm with flat (uniform) prior
metropolis_hastings_mcmc_uniform <- function(n_iterations, F_obs, e_obs) {
  x <- numeric(n_iterations)
  x[1] <- mean(F_obs)  # Initial value

  for (i in 2:n_iterations) {
    proposal <- rnorm(1, mean = x[i-1], sd = 1)
    log_A <- log_posterior_uniform(proposal, F_obs, e_obs) - log_posterior_uniform(x[i-1], F_obs, e_obs)

    if (log(runif(1)) < log_A) {
      x[i] <- proposal  # Accept move
    } else {
      x[i] <- x[i-1]  # Reject and stay where you are
    }
  }

  return(x)
}

# Set seed for reproducibility
set.seed(1)

# Run Metropolis-Hastings MCMC with flat (uniform) prior
mcmc_result_uniform <- metropolis_hastings_mcmc_uniform(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple)

# Plot MCMC trace
plot(mcmc_result_uniform, type = "l", xlab = "Iteration", ylab = "Photon Flux", main = "MCMC Trace with Uniform Prior")

# Burn-in
burn_in_uniform <- 1000
mcmc_result_uniform <- mcmc_result_uniform[(burn_in_uniform + 1):length(mcmc_result_uniform)]

# Plot posterior distribution
hist(mcmc_result_uniform, probability = TRUE, col = "skyblue", main = "Posterior Distribution with Uniform Prior", xlab = "Photon Flux")

# Calculate posterior mean and standard error
posterior_mean_uniform <- mean(mcmc_result_uniform)
posterior_sd_uniform <- sd(mcmc_result_uniform)

# 95% Confidence interval
ci_mcmc_uniform <- quantile(mcmc_result_uniform, c(0.025, 0.975))

# Output results
cat("Posterior Mean with Uniform Prior:", posterior_mean_uniform, "\n")
cat("Posterior Standard Deviation with Uniform Prior:", posterior_sd_uniform, "\n")
cat("95% Credible Interval with Uniform Prior:", ci_mcmc_uniform, "\n")

```





#### Updated prior - Posterior of the previous model will be prior###
```{r}
# Define log prior, likelihood, and posterior functions with flat (uniform) prior
log_prior_uniform <- function(theta) {
  return(0)  # Flat (uniform) prior
}

log_likelihood <- function(theta, F, e) {
  return(-0.5 * sum(log(2 * pi * e^2) + (F - theta)^2 / e^2))
}

log_posterior_uniform <- function(theta, F, e) {
  return(log_prior_uniform(theta) + log_likelihood(theta, F, e))
}

# Metropolis-Hastings MCMC algorithm with flat (uniform) prior
metropolis_hastings_mcmc_uniform <- function(n_iterations, F_obs, e_obs) {
  x <- numeric(n_iterations)
  x[1] <- mean(F_obs)  # Initial value

  for (i in 2:n_iterations) {
    proposal <- rnorm(1, mean = x[i-1], sd = 1)
    log_A <- log_posterior_uniform(proposal, F_obs, e_obs) - log_posterior_uniform(x[i-1], F_obs, e_obs)

    if (log(runif(1)) < log_A) {
      x[i] <- proposal  # Accept move
    } else {
      x[i] <- x[i-1]  # Reject and stay where you are
    }
  }

  return(x)
}

# Set seed for reproducibility
set.seed(1)

# Run Metropolis-Hastings MCMC with flat (uniform) prior
mcmc_result_uniform <- metropolis_hastings_mcmc_uniform(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple)

# Use the posterior of the previous model as the prior for the next model
prior_next_model <- function(theta) {
  # Use the last posterior from the previous model as the prior
  log_posterior_uniform(theta, F_simple, e_simple)
}

# Metropolis-Hastings MCMC algorithm with updated prior
metropolis_hastings_mcmc_updated_prior <- function(n_iterations, F_obs, e_obs, prior_function) {
  x <- numeric(n_iterations)
  x[1] <- mean(F_obs)  # Initial value

  for (i in 2:n_iterations) {
    proposal <- rnorm(1, mean = x[i-1], sd = 1)
    log_A <- prior_function(proposal) - prior_function(x[i-1])

    if (log(runif(1)) < log_A) {
      x[i] <- proposal  # Accept move
    } else {
      x[i] <- x[i-1]  # Reject and stay where you are
    }
  }

  return(x)
}

# Run Metropolis-Hastings MCMC with updated prior
mcmc_result_updated_prior <- metropolis_hastings_mcmc_updated_prior(
  n_iterations = 5000,
  F_obs = F_simple,
  e_obs = e_simple,
  prior_function = prior_next_model
)

# Plot MCMC trace
plot(mcmc_result_updated_prior, type = "l", xlab = "Iteration", ylab = "Photon Flux", main = "MCMC Trace with Updated Prior")

# Burn-in
burn_in_updated_prior <- 1000
mcmc_result_updated_prior <- mcmc_result_updated_prior[(burn_in_updated_prior + 1):length(mcmc_result_updated_prior)]

# Plot posterior distribution
hist(mcmc_result_updated_prior, probability = TRUE, col = "lightgreen", main = "Posterior Distribution with Updated Prior", xlab = "Photon Flux")

# Calculate posterior mean and standard error
posterior_mean_updated_prior <- mean(mcmc_result_updated_prior)
posterior_sd_updated_prior <- sd(mcmc_result_updated_prior)

# 95% Confidence interval
ci_mcmc_updated_prior <- quantile(mcmc_result_updated_prior, c(0.025, 0.975))

# Output results
cat("Posterior Mean with Updated Prior:", posterior_mean_updated_prior, "\n")
cat("Posterior Standard Deviation with Updated Prior:", posterior_sd_updated_prior, "\n")
cat("95% Credible Interval with Updated Prior:", ci_mcmc_updated_prior, "\n")


```



#### Jeffreys Prior- Non-informative Prior####
```{r}
# Define Jeffreys' prior
log_jeffreys_prior <- function(theta) {
  return(-0.5 * log(theta^2))  # Jeffreys' prior
}

# Update log_posterior function to use Jeffreys' prior
log_posterior_jeffreys <- function(theta, F, e) {
  return(log_jeffreys_prior(theta) + log_likelihood(theta, F, e))
}
```

```{r}
# Update metropolis_hastings_mcmc function to accept log_posterior as an argument
set.seed(1)
metropolis_hastings_mcmc <- function(n_iterations, F_obs, e_obs, log_posterior) {
  x <- numeric(n_iterations)
  x[1] <- mean(F_obs)  # Initial value

  for (i in 2:n_iterations) {
    proposal <- rnorm(1, mean = x[i-1], sd = 1)
    log_A <- log_posterior(proposal, F_obs, e_obs) - log_posterior(x[i-1], F_obs, e_obs)

    if (log(runif(1)) < log_A) {
      x[i] <- proposal  # Accept move
    } else {
      x[i] <- x[i-1]  # Reject and stay where you are
    }
  }

  return(x)
}

# Run Metropolis-Hastings MCMC with Jeffreys' prior
mcmc_result_jeffreys <- metropolis_hastings_mcmc(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple, log_posterior = log_posterior_jeffreys)


# Plot MCMC trace with Jeffreys' prior
plot(mcmc_result_jeffreys, type = "l", xlab = "Iteration", ylab = "Photon Flux", main = "MCMC Trace with Jeffreys' Prior")

# Burn-in for the Jeffreys' prior result
burn_in_jeffreys <- 2000
mcmc_result_jeffreys <- mcmc_result_jeffreys[(burn_in_jeffreys + 1):length(mcmc_result_jeffreys)]

# Plot posterior distribution with Jeffreys' prior
hist(mcmc_result_jeffreys, probability = TRUE, col = "lightcoral", main = "Posterior Distribution with Jeffreys' Prior", xlab = "Photon Flux")

# Calculate posterior mean and standard error with Jeffreys' prior
posterior_mean_jeffreys <- mean(mcmc_result_jeffreys)
posterior_sd_jeffreys <- sd(mcmc_result_jeffreys)

# 95% Confidence interval with Jeffreys' prior
ci_mcmc_jeffreys <- quantile(mcmc_result_jeffreys, c(0.025, 0.975))

# Output results with Jeffreys' prior
cat("Posterior Mean with Jeffreys' Prior:", posterior_mean_jeffreys, "\n")
cat("Posterior Standard Deviation with Jeffreys' Prior:", posterior_sd_jeffreys, "\n")
cat("95% Credible Interval with Jeffreys' Prior:", ci_mcmc_jeffreys, "\n")

```

### Codes for all priors  ####
```{r}
# Set seed for reproducibility
set.seed(1)

# True flux and number of measurements
F_true <- 1000
N <- 50

# Generating simple photon count data
F_simple <- rpois(N, F_true)
e_simple <- sqrt(F_simple)

# Visualization for simple photon counts
plot(y = 1:N, x = F_simple, pch = 16, xlab = "Flux", ylab = "Measurement Number",
     main = "Simple Photon Count Data", ylim = c(0, N + 1), yaxt = "n")
arrows(x0 = F_simple - e_simple, x1 = F_simple + e_simple, y0 = 1:N, y1 = 1:N, angle = 90, code = 3)
abline(v = F_true, col = "red", lty = 2, lw = 2)
axis(2, at = 1:N, labels = 1:N)

# Define log prior, likelihood, and posterior functions for flat (uniform) prior
log_prior_flat <- function(theta) {
  return(0)  # Flat (uniform) prior
}

log_likelihood <- function(theta, F, e) {
  return(-0.5 * sum(log(2 * pi * e^2) + (F - theta)^2 / e^2))
}

log_posterior_flat <- function(theta, F, e) {
  return(log_prior_flat(theta) + log_likelihood(theta, F, e))
}

# Define log prior, likelihood, and posterior functions for updating prior
log_posterior_update <- function(theta, F, e) {
  # Use the posterior obtained in the previous case as the prior for the next estimate
  return(log_posterior_flat(theta, F, e))
}

# Define log prior, likelihood, and posterior functions for Jeffreys' prior
log_prior_jeffreys <- function(theta) {
  return(0.5 * log(theta^2))  # Jeffreys' prior
}

log_posterior_jeffreys <- function(theta, F, e) {
  return(log_prior_jeffreys(theta) + log_likelihood(theta, F, e))
}

# Function for Metropolis-Hastings MCMC
metropolis_hastings_mcmc <- function(n_iterations, F_obs, e_obs, log_posterior) {
  x <- numeric(n_iterations)
  x[1] <- mean(F_obs)  # Initial value

  for (i in 2:n_iterations) {
    proposal <- rnorm(1, mean = x[i-1], sd = 1)
    log_A <- log_posterior(proposal, F_obs, e_obs) - log_posterior(x[i-1], F_obs, e_obs)

    if (log(runif(1)) < log_A) {
      x[i] <- proposal  # Accept move
    } else {
      x[i] <- x[i-1]  # Reject and stay where you are
    }
  }

  return(x)
}

# Run Metropolis-Hastings MCMC with flat (uniform) prior
mcmc_result_flat <- metropolis_hastings_mcmc(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple, log_posterior = log_posterior_flat)

# Run Metropolis-Hastings MCMC with updating prior
mcmc_result_update <- metropolis_hastings_mcmc(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple, log_posterior = log_posterior_update)

# Run Metropolis-Hastings MCMC with Jeffreys' prior
mcmc_result_jeffreys <- metropolis_hastings_mcmc(n_iterations = 5000, F_obs = F_simple, e_obs = e_simple, log_posterior = log_posterior_jeffreys)

# Burn-in
burn_in <- 1000
mcmc_result_flat <- mcmc_result_flat[(burn_in + 1):length(mcmc_result_flat)]
mcmc_result_update <- mcmc_result_update[(burn_in + 1):length(mcmc_result_update)]
mcmc_result_jeffreys <- mcmc_result_jeffreys[(burn_in + 1):length(mcmc_result_jeffreys)]

# Calculate posterior mean and standard error for each method
posterior_mean_flat <- mean(mcmc_result_flat)
posterior_sd_flat <- sd(mcmc_result_flat)

posterior_mean_update <- mean(mcmc_result_update)
posterior_sd_update <- sd(mcmc_result_update)

posterior_mean_jeffreys <- mean(mcmc_result_jeffreys)
posterior_sd_jeffreys <- sd(mcmc_result_jeffreys)

# 95% Credible intervals
ci_flat <- quantile(mcmc_result_flat, c(0.025, 0.975))
ci_update <- quantile(mcmc_result_update, c(0.025, 0.975))
ci_jeffreys <- quantile(mcmc_result_jeffreys, c(0.025, 0.975))

# Output results
cat("Flat (Uniform) Prior Method:\n")
cat("Posterior Mean:", posterior_mean_flat, "\n")
cat("Posterior Standard Deviation:", posterior_sd_flat, "\n")
cat("95% Credible Interval:", ci_flat, "\n\n")

cat("Updating Prior Method:\n")
cat("Posterior Mean:", posterior_mean_update, "\n")
cat("Posterior Standard Deviation:", posterior_sd_update, "\n")
cat("95% Credible Interval:", ci_update, "\n\n")

cat("Jeffreys' Prior Method:\n")
cat("Posterior Mean:", posterior_mean_jeffreys, "\n")
cat("Posterior Standard Deviation:", posterior_sd_jeffreys, "\n")
cat("95% Credible Interval:", ci_jeffreys, "\n")

```

###Varying Photons Generation ###

```{r}
set.seed(1)

# Parameters for stochastic flux model
N <- 100
mu_true <- 1000
sigma_true <- 15

# Stochastic flux model
F_true <- rnorm(N, mean = mu_true, sd = sigma_true)

# Observed flux with Poisson error
F <- rpois(N, lambda = F_true)
e <- sqrt(F)

# Visualization for varying photon counts
plot(y = 1:N, x = F, pch = 16, xlab = "Flux", ylab = "Measurement Number",
     main = "Varying Photon Count Data", ylim = c(0, N + 1), yaxt = "n")

# Adding error bars
for (i in 1:N) {
  arrows(x0 = F[i] - e[i], x1 = F[i] + e[i], y0 = i, y1 = i, angle = 90, code = 3, length = 0.1, col = "blue")
}

# True flux dots
points(x = F_true, y = 1:N, col = "red", pch = 16)

# Adding y-axis labels
axis(2, at = 1:N, labels = 1:N)
```
```{r}
library(ggplot2)
library(gridExtra)

# Assuming mcmc_result_uniform, mcmc_result_updated_prior, mcmc_result_jeffreys are vectors containing the MCMC samples

# Create data frames from MCMC results
df_uniform <- data.frame(Flux = mcmc_result_uniform, Prior = 'Uniform')
df_updated <- data.frame(Flux = mcmc_result_updated_prior, Prior = 'Updated')
df_jeffreys <- data.frame(Flux = mcmc_result_jeffreys, Prior = 'Jeffreys')

# Combine data frames
df_combined <- rbind(df_uniform, df_updated, df_jeffreys)

# Convert 'Prior' to a factor for coloring
df_combined$Prior <- as.factor(df_combined$Prior)

# Plot the combined posterior distributions
p <- ggplot(df_combined, aes(x = Flux, fill = Prior)) +
  geom_density(alpha = 0.6) +
  labs(title = 'Comparison of Posterior Distributions for Different Priors',
       x = 'Photon Flux', y = 'Density') +
  scale_fill_brewer(palette = 'Set1') +
  theme_minimal()

# Display the plot
print(p)


```

### Bayesian Approach ##
```{r}
# Function to calculate log likelihood
log_likelihood <- function(theta, F, e) {
  mu <- theta[1]
  sigma <- theta[2]

  # Likelihood for normal distribution
  likelihood <- sum(dnorm(F, mean = mu, sd = sigma, log = TRUE))
  
  return(likelihood)
}

# Function to calculate log prior
log_prior <- function(theta) {
  mu <- theta[1]
  sigma <- theta[2]

  # Prior for mu (assuming a broad prior)
  prior_mu <- dnorm(mu, mean = 0, sd = 100, log = TRUE)

  # Prior for sigma (assuming a broad positive prior)
  prior_sigma <- dunif(sigma, min = 0, max = 100, log = TRUE)

  return(prior_mu + prior_sigma)
}

# Function to calculate log posterior
log_posterior <- function(theta, F, e) {
  return(log_prior(theta) + log_likelihood(theta, F, e))
}

# Metropolis-Hastings MCMC algorithm
metropolis_hastings_mcmc <- function(n_iterations, F, e) {
  theta <- matrix(NA, ncol = 2, nrow = n_iterations)
  theta[1, ] <- c(mean(F), sd(F))  # Initial values

  for (i in 2:n_iterations) {
    proposal <- rnorm(2, mean = theta[i-1, ], sd = c(0.1, 0.1))
    log_A <- log_posterior(proposal, F, e) - log_posterior(theta[i-1, ], F, e)

    if (log(runif(1)) < log_A) {
      theta[i, ] <- proposal  # Accept move
    } else {
      theta[i, ] <- theta[i-1, ]  # Reject and stay where you are
    }
  }

  return(theta)
}

# Set seed for reproducibility
set.seed(1)

# Run Metropolis-Hastings MCMC
n_iterations <- 5000
mcmc_result <- metropolis_hastings_mcmc(n_iterations, F, e)

# Burn-in
burn_in <- 1000
mcmc_result <- mcmc_result[(burn_in + 1):n_iterations, ]

# Calculate posterior mean and standard deviation
posterior_mean <- apply(mcmc_result, 2, mean)
posterior_sd <- apply(mcmc_result, 2, sd)

# 95% Credible intervals
ci_lower <- apply(mcmc_result, 2, function(x) quantile(x, 0.025))
ci_upper <- apply(mcmc_result, 2, function(x) quantile(x, 0.975))

# Output results
cat("Posterior Mean:", posterior_mean, "\n")
cat("Posterior Standard Deviation:", posterior_sd, "\n")
cat("95% Credible Interval (Lower):", ci_lower, "\n")
cat("95% Credible Interval (Upper):", ci_upper, "\n")

```

```{r}
# Plot posterior distribution
hist(mcmc_result[, 1], probability = TRUE, col = "skyblue", main = "Posterior Distribution of mean", xlab = "mean")

# Add a vertical line for the true value of mu
abline(v = mu_true, col = "red", lty = 2)

# Plot density curve
lines(density(mcmc_result[, 1]), col = "darkblue", lty = 2)

# Add legend
legend("topright", legend = c("Posterior Distribution", "True Value", "Density Curve"), 
       col = c("skyblue", "red", "darkblue"), lty = c(1, 2, 2))


```
```{r}
# Function to calculate log likelihood
log_likelihood <- function(theta, F, e) {
  mu <- theta[1]
  sigma <- theta[2]

  # Likelihood for normal distribution
  likelihood <- sum(dnorm(F, mean = mu, sd = sigma, log = TRUE))
  
  return(likelihood)
}

# Function to calculate log prior
log_prior <- function(theta) {
  mu <- theta[1]
  sigma <- theta[2]

  # Prior for mu (assuming a broad prior)
  prior_mu <- dnorm(mu, mean = 0, sd = 100, log = TRUE)

  # Prior for sigma (assuming a broad positive prior)
  prior_sigma <- dunif(sigma, min = 0, max = 100, log = TRUE)

  return(prior_mu + prior_sigma)
}

# Function to calculate log posterior
log_posterior <- function(theta, F, e) {
  return(log_prior(theta) + log_likelihood(theta, F, e))
}

# Metropolis-Hastings MCMC algorithm
metropolis_hastings_mcmc <- function(n_iterations, F, e) {
  theta <- matrix(NA, ncol = 2, nrow = n_iterations)
  theta[1, ] <- c(mean(F), sd(F))  # Initial values

  for (i in 2:n_iterations) {
    proposal <- rnorm(2, mean = theta[i-1, ], sd = c(0.1, 0.1))
    log_A <- log_posterior(proposal, F, e) - log_posterior(theta[i-1, ], F, e)

    if (log(runif(1)) < log_A) {
      theta[i, ] <- proposal  # Accept move
    } else {
      theta[i, ] <- theta[i-1, ]  # Reject and stay where you are
    }
  }

  return(theta)
}

# Set seed for reproducibility
set.seed(1)

# Run Metropolis-Hastings MCMC
n_iterations <- 5000
mcmc_result <- metropolis_hastings_mcmc(n_iterations, F, e)

# Burn-in
burn_in <- 1000
mcmc_result <- mcmc_result[(burn_in + 1):n_iterations, ]

# Plot MCMC trace for mu
plot(mcmc_result[, 1], type = "l", xlab = "Iteration", ylab = expression(mu), main = "MCMC Trace for mean")

# Plot MCMC trace for sigma
plot(mcmc_result[, 2], type = "l", xlab = "Iteration", ylab = expression(sigma), main = "MCMC Trace for error")

```




